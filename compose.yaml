services: 
  ml-services:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        HF_TOKEN: ${HF_TOKEN}
    volumes:
      - .:/ContentSense
      - hf_cache:/root/.cache/huggingface
    ports: 
      - 8000:8000
    environment:
      HF_TOKEN: ${HF_TOKEN}

volumes:
  hf_cache:
